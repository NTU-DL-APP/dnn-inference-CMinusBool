{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q3AJQb14k3vK",
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:42.610909Z",
     "start_time": "2025-06-10T06:04:42.605158Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "YOUR_MODEL_NAME = 'fashion_mnist_model' # Default extension is h5\n",
    "TF_MODEL_PATH = f'{YOUR_MODEL_NAME}.h5'\n",
    "MODEL_WEIGHTS_PATH = f'{YOUR_MODEL_NAME}.npz'\n",
    "MODEL_ARCH_PATH = f'{YOUR_MODEL_NAME}.json'"
   ],
   "metadata": {
    "id": "R5kOVSijmRGF",
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:42.661013Z",
     "start_time": "2025-06-10T06:04:42.651368Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "model = tf.keras.models.load_model(TF_MODEL_PATH)\n",
    "\n",
    "# Save weights to .npz (NumPy format)\n",
    "weights = model.get_weights()\n",
    "np.savez('.model/model_weights.npz', *weights)\n",
    "\n",
    "# Save architecture to JSON\n",
    "with open('model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())\n"
   ],
   "metadata": {
    "id": "4HeolTt5ND_b",
    "outputId": "b0b484ec-5ea5-4575-cba2-6e415e0c6298",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:42.792127Z",
     "start_time": "2025-06-10T06:04:42.731247Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# === Step 1: Load Keras .h5 model ===\n",
    "model = tf.keras.models.load_model(TF_MODEL_PATH)\n",
    "\n",
    "# === Step 2: Print and collect weights ===\n",
    "params = {}\n",
    "print(\"üîç Extracting weights from model...\\n\")\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        for i, w in enumerate(weights):\n",
    "            param_name = f\"{layer.name}_{i}\"\n",
    "            print(f\"  {param_name}: shape={w.shape}\")\n",
    "            params[param_name] = w\n",
    "        print()\n",
    "\n",
    "# === Step 3: Save to .npz ===\n",
    "np.savez(MODEL_WEIGHTS_PATH, **params)\n",
    "print(f\"‚úÖ Saved all weights to {MODEL_WEIGHTS_PATH}\")\n",
    "\n",
    "# === Step 4: Reload and verify ===\n",
    "print(\"\\nüîÅ Verifying loaded .npz weights...\\n\")\n",
    "loaded = np.load(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "for key in loaded.files:\n",
    "    print(f\"{key}: shape={loaded[key].shape}\")\n",
    "\n",
    "# === Step 6: Extract architecture to JSON ===\n",
    "arch = []\n",
    "for layer in model.layers:\n",
    "    config = layer.get_config()\n",
    "    info = {\n",
    "        \"name\": layer.name,\n",
    "        \"type\": layer.__class__.__name__,\n",
    "        \"config\": config,\n",
    "        \"weights\": [f\"{layer.name}_{i}\" for i in range(len(layer.get_weights()))]\n",
    "    }\n",
    "    arch.append(info)\n",
    "\n",
    "with open(MODEL_ARCH_PATH, \"w\") as f:\n",
    "    json.dump(arch, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Architecture saved to model_architecture.json\")"
   ],
   "metadata": {
    "id": "2lqDQAtPl2Y5",
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:42.902311Z",
     "start_time": "2025-06-10T06:04:42.830418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting weights from model...\n",
      "\n",
      "Layer: dense_layer_1\n",
      "  dense_layer_1_0: shape=(784, 128)\n",
      "  dense_layer_1_1: shape=(128,)\n",
      "\n",
      "Layer: output_layer\n",
      "  output_layer_0: shape=(128, 10)\n",
      "  output_layer_1: shape=(10,)\n",
      "\n",
      "‚úÖ Saved all weights to fashion_mnist_model.npz\n",
      "\n",
      "üîÅ Verifying loaded .npz weights...\n",
      "\n",
      "dense_layer_1_0: shape=(784, 128)\n",
      "dense_layer_1_1: shape=(128,)\n",
      "output_layer_0: shape=(128, 10)\n",
      "output_layer_1: shape=(10,)\n",
      "‚úÖ Architecture saved to model_architecture.json\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NN forward Path using Numpy only"
   ],
   "metadata": {
    "id": "XdPYPffGoJek"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# === Load weights and architecture ===\n",
    "weights = np.load(MODEL_WEIGHTS_PATH)\n",
    "with open(MODEL_ARCH_PATH) as f:\n",
    "    architecture = json.load(f)\n",
    "\n",
    "\n",
    "# === Activation functions ===\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e / np.sum(e, axis=-1, keepdims=True)\n",
    "\n",
    "# === Flatten ===\n",
    "def flatten(x):\n",
    "    return x.reshape(x.shape[0], -1)\n",
    "\n",
    "# === Dense layer ===\n",
    "def dense(x, W, b):\n",
    "    return x @ W + b\n",
    "\n",
    "# === Forward pass ===\n",
    "def forward(x):\n",
    "    for layer in architecture:\n",
    "        lname = layer['name']\n",
    "        ltype = layer['type']\n",
    "        cfg = layer['config']\n",
    "        wnames = layer['weights']\n",
    "\n",
    "\n",
    "        if ltype == \"Flatten\":\n",
    "            x = flatten(x)\n",
    "\n",
    "        elif ltype == \"Dense\":\n",
    "            W = weights[wnames[0]]\n",
    "            b = weights[wnames[1]]\n",
    "            x = dense(x, W, b)\n",
    "            if cfg.get(\"activation\") == \"relu\":\n",
    "                x = relu(x)\n",
    "            elif cfg.get(\"activation\") == \"softmax\":\n",
    "                x = softmax(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# === Example usage ===\n",
    "# Load a dummy image (batch size 1)\n",
    "# Make sure it's shape: (1, 28, 28, 1)\n",
    "dummy_input = np.random.rand(1, 28*28).astype(np.float32)\n",
    "output = forward(dummy_input)\n",
    "\n",
    "print(\"üß† Output probabilities:\", output)\n",
    "print(\"‚úÖ Predicted class:\", np.argmax(output, axis=-1))"
   ],
   "metadata": {
    "id": "fXaoHjRxnd7B",
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:43.045650Z",
     "start_time": "2025-06-10T06:04:43.023132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Output probabilities: [[2.8977537e-10 1.4120806e-09 4.4844946e-05 2.4085650e-11 9.3476649e-09\n",
      "  1.4147424e-15 1.1027385e-07 7.0454156e-17 9.9995506e-01 4.9089384e-15]]\n",
      "‚úÖ Predicted class: [8]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "34RfS1ZNOMzb",
    "ExecuteTime": {
     "end_time": "2025-06-10T06:04:43.132684Z",
     "start_time": "2025-06-10T06:04:43.125859Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
